Σταθερές

    USE_CUDA = False --> Δεν χρησιμοποιείται η κάρτα γραφικών του συστήματος.
    EPOCHS = 20 --> Καθορίζει των αριθμό των training epochs για κάθε μοντέλο
    comms_round = 20 --> Είναι ο αριθμός των γύρων επικοινωνίας στο federated learning, μεταξύ των τοπικών μοντέλων και του global model.

Dataset

    %store -r FD1_X_Train_st, FD1_X_Test_st, FD1_y_Train, FD1_y_Test --> Φορτώνονται τα dataframes που περιέχουν το train και το test dataset του CMAPSS.

    merged_dataset = pd.concat([FD1_X_Train_st, FD1_y_Train], axis=1) --> Attributes και target variable γίνονται ένα ενιαίο merged dataset, όπου τα Attributes μπαίνουν στην λίστα feature_columns και η target variable στην RUL.

    Το merged dataset χωρίζεται σε train και test.

Data Partitioning

    Το merged dataset χωρίζεται σε 10 ίσα υποσύνολα, ένα για κάθε μία από τις 10 edge devices. 
    Κάθε ένα από αυτά τα υποσύνολα δεδομένων χωρίζεται σε train και test και αποθηκεύεται ως dictionairy. Κάθε dictionairy περιέχει το όνομα του dataset, τα training features, τα testing features, τα training labels και τα testing labels.

LSTM Model

    Sequential Αρχιτεκτονική Μοντέλου
    Reshape Layer σε (input_shape, 1) για να είναι συμβατό με τα δεδομένα.
    3 LSTM Layers με 128, 64, 32 μονάδες με τη σειρά.
    2 Dense Layers με 64 και 128 μονάδες με τη σειρά, έχοντας την ReLU ως activation function.
    Έξοδος του δικτύου μία single Unit που είναι και η τιμή της πρόβλεψης.

Federated Learning

    Τοπική Εκπαίδευση:
        Σε κάθε γύρο επικοινωνίας (comm_round), τα βάρη του global μοντέλου μοιράζονται στις 10 edge devices. 
        Κάθε edge device εκπαιδεύει το τοπικό της μοντέλο (local_model) χρησιμοποιώντας το δικό της τοπικά σύνολο δεδομένων (dataset['train_features'] και dataset['train_labels']).
        Τα τοπικά μοντέλα εκπαιδεύονται για 20 epochs χρησιμοποιώντας τον βελτιστοποιητή Adam με μια μεταβαλλόμενη τιμή ρυθμού μάθησης, η οποία είναι 0.001 για τα 5 πρώτα epochs και 0.0001 για τα επόμενα 15.
        Μετά την εκπαίδευση, τα τοπικά μοντέλα αξιολογούνται στα αντίστοιχα σύνολα δεδομένων ελέγχου (dataset['test_features'] και dataset['test_labels']) και μέσω print βλέπουμε τα αποτελέσματα.

    Συγκέντρωση Τοπικών Μοντέλων:
        Μετά την τοπική εκπαίδευση συλλέγονται τα ενημερωμένα βάρη από όλες τις edge devices.
        Τα βάρη αυτά γίνονται scaled και έπειτα υπολογίζεται ο μέσος όρος τους (average_weights).
        Τα νέα αυτά βάρη που προέκυψαν έπειτα από τον υπολογισμό του μέσου όρου, ορίζονται ως τα νέα βάρη του global model (global_model.set_weights(average_weights)).

    Αξιολόγηση Global Model:
        Μετά τη συγκέντρωση των τοπικών μοντέλων, η απόδοση του γενικού μοντέλου αξιολογείται σε κάθε σύνολο δεδομένων (dataset['test_features'] και dataset['test_labels']).
        Οι μετρικές αξιολόγησης (MAE, MAPE, RMSE) για κάθε σύνολο δεδομένων και κάθε γύρο επικοινωνίας καταγράφονται στα DataFrames global_stats_mae, global_stats_mape, και global_stats_rmse, αντίστοιχα.

Fedarated Average Aggregation Method

    Μέσω της τεχνικής Federated Average τα τοπικά μοντέλα εκπαιδεύονται σε τοπικά δεδομένα και στη συνέχεια, τα ενημερωμένα βάρη από αυτά τα μοντέλα γίνονται scaled και υπολογίζεται ο μέσος όρος τους για κάθε layer. Το scale που θα δεχτούν εξαρτάται από το μέγεθος των συνόλων δεδομένων, ενώ τα νέα βάρη που προέκυψαν τίθενται ως βάρη του global model.

FedProx Aggregation Method

    Η μέθοδος αυτή αποτελεί στην ουσία επέκταση της Fedarated Average μεθόδου. Χρησιμοποείται μία συνάρτηση για τον υπολογισμό του μέσου όρου των βαρών κάθε layer, όπως και στην FedAvg, ωστόσο εδώ υπεισέρχεται μία μεταβλητή mu, που είναι η σταθερά προσαρμογής. Η συνάρτηση fedprox_update είναι λαμβάνει ως είσοδο τα γενικά βάρη (global_weights) και τα τοπικά βάρη του πελάτη (client_weights), καθώς και την σταθερά mu. Έτσι, τα νέα βάρη του global μοντέλου υπολογίζονται από τον τύπο: updated_w = avg_client_w - mu * (avg_client_w - global_w). Η προσθήκη του όρου mu προσαρμόζει το τοπικό βάρος του πελάτη προς το γενικό βάρος. Ουσιαστικά, αν το τοπικό βάρος είναι κοντά στο γενικό βάρος, η ενημέρωση είναι μικρή, ενώ αν τα δύο βάρη είναι απομακρυσμένα, η ενημέρωση είναι μεγαλύτερη. Αυτό επιτυγχάνει την κανονικοποίηση της ενημέρωσης των βαρών, βοηθώντας στην εξομάλυνση της απόκλισης μεταξύ των τοπικών και των γενικών βαρών, κάτι που συνήθως επιτυγχάνεται με την κανονικοποίηση της εκπαίδευσης.

Weighted Based on Eval Metrics

    Στην μέθοδο αυτή για την καλύτερη ανανέωση των βαρών του global model, λαμβάνεται υπόψη το Μέσο Απόλυτο Σφάλμα, το ποσοστό Μέσου Απόλυτου Σφάμλατος και η ρίζα Μέσου Τετραγωνικού Σφάλματος του κάθε τοπικού μοντέλου. Για κάθε μοντέλο βάσει της απόδοσής του υπολογίζεται ένα παράγοντας βάρους, ο οποίος είναι υπεύθυνος για την συνεισφορά του εκάστοτε τοπικού μοντέλου και των βαρών του στο global μοντέλο. Έτσι, στη συνέχεια για κάθε layer υπολογίζεται το άθροισμα των βαρών όλων των τοπικών μοντέλων, διαιρεμένο με το συνολικό βάρος. Με τον τρόπο αυτό το global μοντέλο επηρεάζεται περισσότερο από τα τοπικά μοντέλα που έχουν υψηλότερη απόδοση. 

KRUM

    Η μέθοδος Krum για federated learning έχει ως στόχο να συγκεντρώσει τα τοπικά μοντέλα από τους clients με τρόπο που να είναι ανθεκτικός σε Byzantine επιθέσεις. Ακολουθεί τα παρακάτω βήματα:

    Υπολογισμός Αποστάσεων: Αρχικά, για κάθε ζεύγος τοπικών μοντέλων (weights) που έχουν σταλεί από τους clients, υπολογίζεται η Ευκλείδεια απόσταση. Η απόσταση αυτή μετρά την "διαφορά" μεταξύ των δύο μοντέλων σε επίπεδο παραμέτρων (weights) και αποθηκεύεται σε έναν πίνακα αποστάσεων.

    Υπολογισμός Σκορ (Scores): Για κάθε μοντέλο, υπολογίζεται ένα σκορ που αντικατοπτρίζει το πόσο "κοντά" είναι στα άλλα μοντέλα. Το σκορ αυτό υπολογίζεται αθροίζοντας τις αποστάσεις του μοντέλου από τα n - f - 2 πιο κοντινά μοντέλα, όπου n είναι ο συνολικός αριθμός των clients και f ο αριθμός των Byzantine clients. Δηλαδή, εξαιρούνται οι μεγαλύτερες αποστάσεις για να μειωθεί η επίδραση των κακόβουλων ή ελαττωματικών μοντέλων.

    Επιλογή του Καλύτερου Μοντέλου: Το μοντέλο που έχει το μικρότερο συνολικό σκορ επιλέγεται ως το συγκεντρωτικό μοντέλο (aggregated model). Αυτό σημαίνει ότι το επιλεγμένο μοντέλο είναι το πιο αντιπροσωπευτικό ή "κεντρικό" σε σχέση με τα υπόλοιπα μοντέλα, λαμβάνοντας υπόψη ότι μπορεί να υπάρχουν κακόβουλοι clients που στέλνουν λανθασμένα μοντέλα.

    Ενημέρωση του Παγκόσμιου Μοντέλου (Global Model): Τα βάρη (weights) του επιλεγμένου μοντέλου χρησιμοποιούνται για την ενημέρωση του παγκόσμιου μοντέλου, το οποίο στη συνέχεια αποστέλλεται πίσω στους clients για τον επόμενο γύρο εκπαίδευσης.
